{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import word2vec \n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors=KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted, rejected = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_acceptance(word):\n",
    "    \n",
    "    x = cosine_similarity(word_vectors['food'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "    y = cosine_similarity(word_vectors['culinary'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "    z = cosine_similarity(word_vectors['recipe'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "    w = cosine_similarity(word_vectors['ingredient'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "    a = cosine_similarity(word_vectors['drink'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "    b = cosine_similarity(word_vectors['utensil'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "\n",
    "\n",
    "    if x>0.50 or y>=0.50 or z>0.50 or w>0.50 or a>0.50 or b>0.50:\n",
    "        accepted.append(word)\n",
    "    else:\n",
    "        rejected.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    with open('dataset.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            for word in line.split():\n",
    "                check_acceptance(word)\n",
    "\n",
    "    with open('accepted.txt', 'w') as f:\n",
    "        for word in accepted:\n",
    "            f.write(word + '\\n')\n",
    "\n",
    "    with open('rejected.txt', 'w') as f:\n",
    "        for word in rejected:\n",
    "            f.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m start()\n",
      "Cell \u001b[1;32mIn [6], line 2\u001b[0m, in \u001b[0;36mstart\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstart\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mdataset.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m             \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m line\u001b[39m.\u001b[39msplit():\n",
      "File \u001b[1;32mc:\\Users\\verma\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset.txt'"
     ]
    }
   ],
   "source": [
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_pretrained_dict = dict(zip(word_vectors.key_to_index.keys(),  word_vectors.vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000000/3000000 [3:32:33<00:00, 235.23it/s]  \n"
     ]
    }
   ],
   "source": [
    "word2vec_generated_words = []\n",
    "from tqdm import tqdm\n",
    "for word in tqdm(word2vec_pretrained_dict.keys()):\n",
    "    x = cosine_similarity(word_vectors['food'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "    y = cosine_similarity(word_vectors['culinary'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "    z = cosine_similarity(word_vectors['recipe'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "    w = cosine_similarity(word_vectors['ingredient'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "    a = cosine_similarity(word_vectors['drink'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "    b = cosine_similarity(word_vectors['utensil'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "    c = cosine_similarity(word_vectors['cook'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "    d = cosine_similarity(word_vectors['chef'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "    e = cosine_similarity(word_vectors['dinner'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "    f = cosine_similarity(word_vectors['meal'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "    g = cosine_similarity(word_vectors['dining'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "    h = cosine_similarity(word_vectors['restaurant'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "    i = cosine_similarity(word_vectors['cuisine'].reshape(1,-1),word_vectors[word].reshape(1,-1))\n",
    "\n",
    "    if x>0.50 or y>=0.50 or z>0.50 or w>0.50 or a>0.50 or b>0.50 or c>0.50 or d>0.50 or e>0.50 or f>0.50 or g>0.50 or h>0.50 or i>0.50:\n",
    "        if len(word)>=3:\n",
    "            word2vec_generated_words.append(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(word2vec_generated_words, columns=['names']).to_csv('lets_see.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted = []\n",
    "remove = []\n",
    "for x in word2vec_generated_words:\n",
    "    if len(x.split(\"_\"))>1:\n",
    "        remove.append(x)\n",
    "        for y in x.split(\"_\"):\n",
    "            splitted.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_generated_words = [x for x in word2vec_generated_words if x not in remove]\n",
    "for y in splitted:\n",
    "    word2vec_generated_words.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_generated_words = list(set(word2vec_generated_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(word2vec_generated_words)):\n",
    "    word2vec_generated_words[i] = word2vec_generated_words[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(word2vec_generated_words, columns=['names']).to_csv('lets_see.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enchant\n",
    "d = enchant.Dict(\"en_US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted = []\n",
    "rejected = []\n",
    "for x in word2vec_generated_words:\n",
    "    if len(x)==0:\n",
    "        continue\n",
    "    if d.check(x):\n",
    "        accepted.append(x)\n",
    "    else:\n",
    "        rejected.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(accepted, columns=['names']).to_csv('words_enUS.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rejected, columns=['names']).to_csv('words_notUS.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1 (tags/v3.8.1:1b293b6, Dec 18 2019, 23:11:46) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22475eb23e40dd7b65ba6ce08c4232f330744b78bf0f395659ba2343c9d6fca6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
